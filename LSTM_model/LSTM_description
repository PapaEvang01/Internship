LSTM-Based Cooling Load Forecasting  
Author: [Your Name]

=== Theoretical Background ===

The Long Short-Term Memory (LSTM) network is a specialized architecture within Recurrent Neural Networks (RNNs) designed to handle sequential data. 
Traditional RNNs struggle with learning long-range dependencies due to vanishing gradients. LSTM overcomes this by introducing memory cells and gating mechanisms that regulate information flow over time.

Each LSTM unit contains:
- **Cell State (C):** Long-term memory that persists across time steps
- **Forget Gate (f):** Decides what information to discard
- **Input Gate (i):** Determines what new data to store
- **Output Gate (o):** Chooses what part of the memory to expose

This structure allows LSTM models to remember important signals over long periods while ignoring noise and irrelevant fluctuations — ideal for time series tasks like energy forecasting.

=== Why Use LSTM for This Project ===

This project focuses on forecasting *cooling energy loads* based on past consumption patterns recorded at 15-minute intervals throughout 2023.
Such data contains both short-term (hourly/daily) and long-term (seasonal) dependencies.

LSTM is well-suited for this task because it can:
- Learn from long historical sequences
- Capture both nonlinear trends and hidden seasonality
- Perform well even without external inputs (like weather data)

The goal is to predict daily cooling energy consumption for December 2023 based on earlier patterns.

=== Input Data Description ===

- **File Format:** Excel (.xlsx)
- **Resolution:** 15-minute intervals
- **Date Range:** January 1 – December 31, 2023
- **Total Entries:** 35,040 (96 per day × 365 days)

**Columns:**
1. **Timestamp** (e.g., "1/1/23 0:00") – beginning of each 15-minute interval
2. **Cooling Load (kWh)** – energy used during the interval, stored using commas as decimal separators (e.g., "0,08")

Preprocessing is required to:
- Convert timestamps to Python `datetime`
- Replace commas with periods and cast load values to float

**Sample (first 5 rows):**
| Timestamp     | kWh  |
|---------------|------|
| 1/1/23 0:00   | 0,08 |
| 1/1/23 0:15   | 0,05 |
| 1/1/23 0:30   | 0,05 |
| 1/1/23 0:45   | 0,04 |
| 1/1/23 1:00   | 0,07 |

=== Model Architecture & Workflow ===

**Framework:** TensorFlow / Keras  
**Target:** Univariate forecasting (cooling load only)  
**Input:** Past `n` time steps of cooling load  
**Output:** Forecasted next value(s)

**Main Steps:**
1. Load the full-year dataset (35,040 rows)
2. Split into training (Jan–Nov, 32,065 entries) and testing (Dec, 2,975 entries)
3. Normalize data using Min-Max scaling
4. Create sliding input sequences for the LSTM
5. Train the model over 20 epochs using a zero-sensitive loss function
6. Save trained model as `cooling_lstm_fullmodel.pth`
7. Forecast all December values and compare with ground truth

=== Folder Structure ===

LSTM_model/
│
├── code/
│   └── cooling_Loads_predictions_with_LSTM.ipynb   # Main notebook: loading data, training LSTM, forecasting
│
├── inputs/                                         # Folder with input dataset
│
├── results/                                        # Folder with generated outputs

Visualization Outputs:
- `cooling_december_prediction.png` – actual vs predicted (December only)
- `cooling_actual_full_year.png` – raw 2023 consumption plot
- `full_year_with_december_overlay.png` – predicted December overlayed on real yearly trend

=== Results & Evaluation ===

Final model performance (on denormalized data):

- **MAE:** 0.065 kWh  
  → On average, the model deviates by just 0.065 kWh

- **RMSE:** 0.167 kWh  
  → Low variance in errors, indicating stability

- **R² Score:** 0.938  
  → 93.8% of the variance in actual values is explained by the model

- **MAPE:** ~1.6e15%  
  → Inflated due to division by small/near-zero actual values  
  ⚠️ *Recommendation:* Filter out entries with load < 0.1 kWh when computing MAPE

**Observations:**
- The model captures both short- and long-term structure effectively
- No external variables were used (purely historical load), yet performance is excellent
- Future work could explore multivariate inputs (e.g., temperature, humidity)

=== Conclusion ===

This project demonstrates the effectiveness of LSTM in forecasting high-resolution energy time series. The model achieved high accuracy in predicting December cooling loads with minimal noise and consistent generalization. The workflow and results suggest LSTM is a strong candidate for energy demand forecasting, particularly in smart grid or building management systems.

